<img width="136" alt="Aftertaste_logo" src="https://github.com/user-attachments/assets/4c7f9157-6613-445d-afe6-32000e2882a1" />


# Aftertaste

Aftertaste calculates CO2 emissions, land use, and water use of various food items. It additionally gives an ingredient-by-ingredient analysis of CO2 emissions in that particular food item. Users can either scan the barcode of a packaged food item or take an image of particular dish.

## Demo

Demo of taking a picture of a food dish:

https://drive.google.com/file/d/137ZONrwQ90dX4xp2YaJRP0pelaqKwM0q/view?usp=sharing


Demo of scanning a barcode of a packaged food item:

https://drive.google.com/file/d/1P8Qr9hviFX_dzV5T9t_1XwwmXXeT5KcX/view?usp=sharing


## Development

This app was created with a Flutter frontend and a Python backend (via Flask).The OpenFoodFacts API was used to identify packaged items from barcodes (https://world.openfoodfacts.org/data). A trained food segmentation model with an mIOU score of 0.5680 (fairly accurate) was used to determine ingredients and their proportions within the image. The link to the trained model can be found here: https://www.kaggle.com/code/ishitamundra/foodseg103-try-1. Finally, text embeddings generated by the all-MiniLM-L6-v2 Sentence Transformer were used to map ingredients to the Food_CO2_Emissions_Dataset (https://www.kaggle.com/datasets/selfvivek/environment-impact-of-food-production) via cosine similarities. 
